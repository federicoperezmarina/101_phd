# Follow-up — 2025-05-06

## Last Follow-up Actions

1. **Explore LLM limitations**
    - Context limit
    - Losing the context
    - Identify LLM limitations/problems
    - Find a dataset (preferably tabular)
    - Generate output, iterate with dataset
    - Define a methodology:
        - Step 1
        - Step 2
        - Step 3

2. **Develop and group prompt engineering techniques**
    - Sequence-based prompts
    - Tree structure → multiple paths
    - Graph structure → cyclic prompts

---

## Things DONE

### Coding Examples — LLaMA 3.2

**Limitations Observed:**
- Supported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, Thai
- Is the LLM censored?
- Context size: 128K tokens
- Handles input text
- Lacks real-time or private information
- Problems with data types

**Test Scripts:**

| Script             | Language / Test Type | Status | Output / Notes                                                                                      |
|--------------------|----------------------|--------|-----------------------------------------------------------------------------------------------------|
| `llm_limit_1.py`   | English              | ✅     | `"127.0.0.1 - - [15/Jul/2019:13:34:09 +0000] 'GET /index.html HTTP/1.1' 200 1234"`                  |
| `llm_limit_2.py`   | Spanish              | ✅     | `"GET /static/file.txt HTTP/1.1 200 1234"`                                                          |
| `llm_limit_3.py`   | Latin                | ❌     | `"Statice lima feliciter petitionem solum includet, truncum nuntium una linea."`<br>LLM not trained |
| `llm_limit_4.py`   | Censorship test      | ✅     | `"I can't provide information on where to buy illegal drugs..."`                                    |
| `llm_limit_5.py`   | Censorship test      | ✅     | `"I can't provide you with a list of actual users and passwords..."`                                |
| `llm_limit_6.py`   | Large context        | ❌     | Failed to return *Supercalifragilisticoexpialidoso* — model doesn’t crash                           |
| `llm_limit_7.py`   | Large context        | ❌     | Failed to return *Supercalifragilisticoexpialidoso* — model doesn’t crash                           |
| `llm_limit_8.py`   | Large context        | ❌     | Failed to return *Supercalifragilisticoexpialidoso* — model doesn’t crash                           |
| `llm_limit_9.py`   | Small context        | ✅     | `"Supercalifragilisticoexpialidoso"`                                                                |
| `llm_limit_10.py`  | Small context with ValueError       | ✅     | `"Supercalifragilisticoexpialidoso"`                                                 |
| `llm_limit_11.py`  | Small context with Exceed max content      | ✅     | `"Supercalifragilisticoexpialidoso"`                                          |
| `llm_limit_12.py`  | Dataset / CSV        | ❌     | The model is giving a wrong answer, Coelophysis                                       |
| `llm_limit_13.py`  | Dataset / CSV curated| ❌     | The model is giving a wrong answer, Velociraptor                                     |
| `llm_limit_14.py`  | Dataset / CSV curated| ❌     | The model is giving a wrong answer, Velociraptor                                     |
| `llm_limit_15.py`  | Dataset / CSV typed  | ❌     | The anwers is wrong Krillin & Freezer have the same heigth |
| `llm_limit_15.py`  | Dataset / CSV typed  | ❌     | The anwers is wrong Broly is the most heavy |

#### Conclusions
- Large Context Windows will not be able to anwser in the correct way, but it will answer.
- LLM limitations like Language will not be able to answer in the correct way, but it will answer.
- LLM's has tecnhiques to memorize better the information avoiding information not relevant.
- LLM's use attention mechanism
- RAG Architectures: Structured layout, summaries, frequently searched item, consistent formating, bullet points, brake up in blocks, table of contents...
- Ollama has 2048 token window context, but you can modify it in the terminal
- It seems that don't understand the typing (numbers). The llm recieves a text, it is not understanding the types.
- You can only ask for one question otherwise the llm get confused

#### Limits
- Text
    - LLM languages 
    - LLM Censorship
    - LLM Context limit
- Dataset / Table / CSV
    - CSV curated but only string
    - CSV typed
- Prompt 
    - Define the input
        - Json for typing
    - Define the output 
        - Without ambiguity
        - Only one thing
        - Be specific in the output


### Papers

**Large Language Model Guided Tree-of-Thought**
- [Paper: Large Language Model Guided Tree-of-Thought](https://github.com/federicoperezmarina/101_phd/tree/main/papers/2201.08291)
- Abstract: In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressivelarge language models (LLMs). The ToT technique is inspired by the human mind’s approach for solving complex reasoning tasks through trial and error. In this process, the human mind explores the solution space through a tree-like thought process, allowing for backtracking when necessary. To implement ToT as a software system, we augment an LLM with additional modules including a prompter agent, a checker module, a memory module, and a ToT controller. In order to solve a given problem, these modules engage in a multi-round conversation with the LLM. The memory module records the conversation and state history of the problem solving process, which allows the system to backtrack to the previous steps of the thought-process and explore other directions from there. To verify the effectiveness of the proposed technique, we implemented a ToT-based solver for the Sudoku Puzzle. Experimental results show that the ToT framework can significantly increase the success rate of Sudoku puzzle solving. Our implementation of the ToT-based Sudoku solver is available on GitHub: https://github.com/jieyilong/tree-of-thought-puzzle-solver.

![ToT Technique](https://raw.githubusercontent.com/federicoperezmarina/101_phd/main/papers/2305.08291/ToT_technique.png)


**Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Language Models**
- [Paper: Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Language Models](https://github.com/federicoperezmarina/101_phd/tree/main/papers/2201.16582)
- Abstract: With the widespread use of language models (LMs) in NLP tasks, researchers have discovered the potential of Chain-of-thought (CoT) to assist LMs in accomplishing complex reasoning tasks by generating intermediate steps. However, human thought processes are often non-linear, rather than simply sequential chains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning, which models human thought processes not only as a chain but also as a graph. By representing thought units as nodes and connections between them as edges, our approach captures the non-sequential nature of human thinking and allows for a more realistic modeling of thought processes. GoT adopts a two-stage framework with an additional GoT encoder for thought graph representation and fuses the graph representation with the original input representation through a gated fusion mechanism. We evaluate GoT’s performance on a text-only reasoning task (AQUA-RAT) and a multimodal reasoning task (ScienceQA). Our model achieves significant improvement over the strong CoT baseline on the AQUA-RAT test set and boosts accuracy from 85.19% to 87.59% using the T5-base model over the state-of-theart Multimodal-CoT (Zhang et al., 2023) on the ScienceQA test set. Our code is publicly available at https://github.com/Zoeyyao27/Graphof-Thought

![GoT Technique](https://raw.githubusercontent.com/federicoperezmarina/101_phd/main/papers/2305.16582/GoT_techinque.png)

---

## Next Steps

_(To be defined)_