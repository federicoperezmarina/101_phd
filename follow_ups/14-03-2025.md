# Follow-up 14-03-2025

## Generation with Ollama
- Generation with Ollama 3.2 - Generic LLM 
- Prompt engineering:
    - Zero-shot
    - One-shot
    - Few-shot 
    - Multi-step generation

- [zero-shot prompting with ollama](https://github.com/federicoperezmarina/101_phd/blob/main/code/zero_shot_ollama_3_2.py)
- [one-shot prompting with ollama](https://github.com/federicoperezmarina/101_phd/blob/main/code/one_shot_ollama_3_2.py)
- [few-shot prompting with ollama](https://github.com/federicoperezmarina/101_phd/blob/main/code/few_shot_ollama_3_2.py)
- [multi-step prompting with ollama](https://github.com/federicoperezmarina/101_phd/blob/main/code/multi_step_ollama_3_2.py)

## Data Validation
- There is a python library validator [Pydantic](https://docs.pydantic.dev/latest/)
- You can use its own validators and also you can create custom.

## Next Actions

