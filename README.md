# 101_phd
This repository is going to explain all the steps given by me in order to do my phd.

A very useful step is to read a metapaper of papers which explains how to read papers. [PDF](paper-reading.pdf)

## Papers
| Paper | Useful |
|---|---|
|[On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](https://github.com/federicoperezmarina/101_phd/tree/main/2406.15126) | :white_check_mark: |
|[DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://github.com/federicoperezmarina/101_phd/tree/main/2402.10379) | :white_check_mark: |
|[Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations](https://github.com/federicoperezmarina/101_phd/tree/main/2310.07849) | :white_check_mark: |
|[Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://github.com/federicoperezmarina/101_phd/tree/main/2406.20094) | :x: |
|[The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussion](https://github.com/federicoperezmarina/101_phd/tree/main/2406.12480)| :white_check_mark: |
|[MedSyn: LLM-based Synthetic Medical TextGeneration Framework](https://github.com/federicoperezmarina/101_phd/tree/main/2408.02056)| :white_check_mark: |


## Data Generation

### How to generate Synthetic Data?
- With a generic LLM
    - Give Context to the LLM
    - Prompt engineering:
        - Zero-shot
        - Few-shot / Multi-step generation
- With specialized LLM (Model trained for specific tasks)
    - Prompt engineering:
        - Zero-shot
        - Few-shot / Multi-step generation

### What can I use? (Tools)
- LangChain
- DataDreamer


- Gaps en la Survey que hay. 
- Metodologia para el fine tuning de un modelo
- 